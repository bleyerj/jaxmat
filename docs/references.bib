%General
@book{simo2006computational,
  title={Computational inelasticity},
  author={Simo, Juan C and Hughes, Thomas JR},
  volume={7},
  year={2006},
  publisher={Springer Science \& Business Media}
}


@book{bonnet2014finite,
  title={The finite element method in solid mechanics},
  author={Bonnet, Marc and Frangi, Attilio and Rey, Christian},
  year={2014},
  publisher={McGraw-Hill Education New York},
  isbn = {978-8838674464},
}

%plasticity
@article{seidl2022calibration,
  title={Calibration of elastoplastic constitutive model parameters from full-field data with automatic differentiation-based sensitivities},
  author={Seidl, D Thomas and Granzow, Brian N},
  journal={International Journal for Numerical Methods in Engineering},
  volume={123},
  number={1},
  pages={69--100},
  year={2022},
  publisher={Wiley Online Library}
}
@article{miehe2002anisotropic,
  title={Anisotropic additive plasticity in the logarithmic strain space: modular kinematic formulation and implementation based on incremental minimization principles for standard materials},
  author={Miehe, Christian and Apel, Nikolas and Lambrecht, Matthias},
  journal={Computer methods in applied mechanics and engineering},
  volume={191},
  number={47-48},
  pages={5383--5425},
  year={2002},
  publisher={Elsevier}
}



%Optimization elastoplasticity
@article{krabbenhoft2007formulation,
  title={Formulation and solution of some plasticity problems as conic programs},
  author={Krabbenh{\o}ft, K and Lyamin, AV and Sloan, SW},
  journal={International Journal of Solids and Structures},
  volume={44},
  number={5},
  pages={1533--1549},
  year={2007},
  publisher={Elsevier}
}
@article{bisbos2007second,
  title={Second-order cone and semidefinite representations of material failure criteria},
  author={Bisbos, Christos D and Pardalos, Panos M},
  journal={Journal of Optimization Theory and Applications},
  volume={134},
  number={2},
  pages={275--301},
  year={2007},
  publisher={Springer}
}
@article{bruno2020return,
  title={Return-mapping algorithms for associative isotropic hardening plasticity using conic optimization},
  author={Bruno, Hugo and Barros, Guilherme and Menezes, Ivan FM and Martha, Luiz Fernando},
  journal={Applied Mathematical Modelling},
  volume={78},
  pages={724--748},
  year={2020},
  publisher={Elsevier}
}
%IPM
@Article{andersen2003implementing,
  author    = {Andersen, Erling D and Roos, Cornelis and Terlaky, Tamas},
  title     = {On implementing a primal-dual interior-point method for conic quadratic optimization},
  journal   = {Mathematical Programming},
  year      = {2003},
  volume    = {95},
  number    = {2},
  pages     = {249--277},
  publisher = {Springer},
}
@article{bleyer2021automated,
  title={Automated formulation and resolution of limit analysis problems},
  author={Bleyer, Jeremy and Hassen, Ghazi},
  journal={Computers \& Structures},
  volume={243},
  pages={106341},
  year={2021},
  publisher={Elsevier}
}


%CVXPY
@article{diamond2016cvxpy,
  author  = {Steven Diamond and Stephen Boyd},
  title   = {{CVXPY}: {A} {P}ython-embedded modeling language for convex optimization},
  journal = {Journal of Machine Learning Research},
  year    = {2016},
  volume  = {17},
  number  = {83},
  pages   = {1--5},
}

@article{agrawal2018rewriting,
  title={A rewriting system for convex optimization problems},
  author={Agrawal, Akshay and Verschueren, Robin and Diamond, Steven and Boyd, Stephen},
  journal={Journal of Control and Decision},
  volume={5},
  number={1},
  pages={42--60},
  year={2018},
  publisher={Taylor \& Francis}
}

@article{agrawal2019differentiable,
  title={Differentiable convex optimization layers},
  author={Agrawal, Akshay and Amos, Brandon and Barratt, Shane and Boyd, Stephen and Diamond, Steven and Kolter, J Zico},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@InProceedings{amos2017icnn,
  title = 	 {Input Convex Neural Networks},
  author =       {Brandon Amos and Lei Xu and J. Zico Kolter},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {146--155},
  year = 	 {2017},
  editor = 	 {Precup, Doina and Teh, Yee Whye},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--11 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/amos17b/amos17b.pdf},
  url = 	 {https://proceedings.mlr.press/v70/amos17b.html},
  abstract = 	 {This paper presents the input convex neural network architecture. These are scalar-valued (potentially deep) neural networks with constraints on the network parameters such that the output of the network is a convex function of (some of) the inputs. The networks allow for efficient inference via optimization over some inputs to the network given others, and can be applied to settings including structured prediction, data imputation, reinforcement learning, and others. In this paper we lay the basic groundwork for these models, proposing methods for inference, optimization and learning, and analyze their representational power. We show that many existing neural network architectures can be made input-convex with a minor modification, and develop specialized optimization algorithms tailored to this setting. Finally, we highlight the performance of the methods on multi-label prediction, image completion, and reinforcement learning problems, where we show improvement over the existing state of the art in many cases.}
}

% JAX
@misc{jax2018github,
  author = {James Bradbury and Roy Frostig and Peter Hawkins and Matthew James Johnson and Chris Leary and Dougal Maclaurin and George Necula and Adam Paszke and Jake Vander{P}las and Skye Wanderman-{M}ilne and Qiao Zhang},
  title = {{JAX}: composable transformations of {P}ython+{N}um{P}y programs},
  url = {http://github.com/google/jax},
  version = {0.3.13},
  year = {2018},
}

%MFront
@article{helfer2020mfrontgenericinterfacesupport,
  title={The MFrontGenericInterfaceSupport project},
  author={Helfer, Thomas and Bleyer, Jeremy and Frondelius, Tero and Yashchuk, Ivan and Nagel, Thomas and Naumov, Dmitri},
  journal={Journal of Open Source Software},
  volume={5},
  number={48},
  pages={1--8},
  year={2020},
  publisher={Open Journals}
}

@article{helfer2015introducing,
  title={Introducing the open-source mfront code generator: Application to mechanical behaviours and material knowledge management within the PLEIADES fuel element modelling platform},
  author={Helfer, Thomas and Michel, Bruno and Proix, Jean-Michel and Salvo, Maxime and Sercombe, J{\'e}r{\^o}me and Casella, Michel},
  journal={Computers \& Mathematics with Applications},
  volume={70},
  number={5},
  pages={994--1023},
  year={2015},
  publisher={Elsevier}
}

% PANN hyperelasticity


@article{maurer_utilizing_2024,
	title = {Utilizing physics-augmented neural networks to predict the material behavior according to {Yeoh}'s law},
	volume = {24},
	issn = {1617-7061},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pamm.202400213},
	doi = {10.1002/pamm.202400213},
	abstract = {This article discusses physics-augmented neural network approaches in the field of hyperelastic material modeling. Physical conditions such as objectivity, material symmetry, or a stress– and energy-free reference configuration are considered in the construction of the neural networks. In addition, a new approach for stress normalization is proposed. The neural network is used to learn the behavior of Yeoh's constitutive model with sparse data. Finally, the trained networks are incorporated into a three-dimensional finite element framework and compared with the classical material model in terms of accuracy. The paper demonstrates the ability of physics-augmented neural networks to model hyperelastic materials using a small amount of data that could be generated by experiments. Compared to the classical constitutive laws of Yeoh's model, our trained material showed no material instabilities that could occur due to poorly chosen material parameters.},
	language = {en},
	number = {4},
	urldate = {2025-10-03},
	journal = {PAMM},
	author = {Maurer, Lukas and Eisenträger, Sascha and Kalina, Karl and Juhre, Daniel},
	year = {2024},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/pamm.202400213},
	pages = {e202400213},
	file = {Full Text PDF:/home/bleyerj/Zotero/storage/852MQWHN/Maurer et al. - 2024 - Utilizing physics-augmented neural networks to pre.pdf:application/pdf;Snapshot:/home/bleyerj/Zotero/storage/8FC6H4CV/pamm.html:text/html},
}

@article{linden_neural_2023,
	title = {Neural networks meet hyperelasticity: {A} guide to enforcing physics},
	volume = {179},
	issn = {0022-5096},
	shorttitle = {Neural networks meet hyperelasticity},
	url = {https://www.sciencedirect.com/science/article/pii/S0022509623001679},
	doi = {10.1016/j.jmps.2023.105363},
	abstract = {In the present work, a hyperelastic constitutive model based on neural networks is proposed which fulfills all common constitutive conditions by construction, and in particular, is applicable to compressible material behavior. Using different sets of invariants as inputs, a hyperelastic potential is formulated as a convex neural network, thus fulfilling symmetry of the stress tensor, objectivity, material symmetry, polyconvexity, and thermodynamic consistency. In addition, a physically sensible stress behavior of the model is ensured by using analytical growth terms, as well as normalization terms which ensure the undeformed state to be stress free and with zero energy. In particular, polyconvex, invariant-based stress normalization terms are formulated for both isotropic and transversely isotropic material behavior. By fulfilling all of these conditions in an exact way, the proposed physics-augmented model combines a sound mechanical basis with the extraordinary flexibility that neural networks offer. Thus, it harmonizes the theory of hyperelasticity developed in the last decades with the up-to-date techniques of machine learning. Furthermore, the non-negativity of the hyperelastic neural network-based potentials is numerically examined by sampling the space of admissible deformations states, which, to the best of the authors’ knowledge, is the only possibility for the considered nonlinear compressible models. For the isotropic neural network model, the sampling space required for that is reduced by analytical considerations. In addition, a proof for the non-negativity of the compressible Neo-Hooke potential is presented. The applicability of the model is demonstrated by calibrating it on data generated with analytical potentials, which is followed by an application of the model to finite element simulations. In addition, an adaption of the model to noisy data is shown and its extrapolation capability is compared to models with reduced physical background. Within all numerical examples, excellent and physically meaningful predictions have been achieved with the proposed physics-augmented neural network.},
	urldate = {2025-10-03},
	journal = {Journal of the Mechanics and Physics of Solids},
	author = {Linden, Lennart and Klein, Dominik K. and Kalina, Karl A. and Brummund, Jörg and Weeger, Oliver and Kästner, Markus},
	month = oct,
	year = {2023},
	keywords = {Anisotropy, Constitutive modeling, Finite element simulation, Hyperelasticity, Normalization, Physics-augmented neural networks},
	pages = {105363},
	file = {ScienceDirect Snapshot:/home/bleyerj/Zotero/storage/E9P2FUEY/S0022509623001679.html:text/html;Submitted Version:/home/bleyerj/Zotero/storage/MPAEZBK8/Linden et al. - 2023 - Neural networks meet hyperelasticity A guide to e.pdf:application/pdf},
}
@article{treloar1944stress,
  title={Stress-strain data for vulcanized rubber under various types of deformation},
  author={Treloar, Leslie RG},
  journal={Rubber Chemistry and Technology},
  volume={17},
  number={4},
  pages={813--825},
  year={1944}
}

% Cam-Clay
@article{bacquaert2024standard,
  title={A standard thermodynamic-based extension of the Modified Cam-Clay soil model and its applications},
  author={Bacquaert, G and Raude, S and Alves-Fernandes, V and Voldoire, F and Kondo, D},
  journal={European Journal of Mechanics-A/Solids},
  volume={103},
  pages={105122},
  year={2024},
  publisher={Elsevier}
}

% MEALOR
@misc{besson2023mealor,
  title={MEALOR II Damage Mechanics and Local Approach to Fracture},
  author={Besson, Jacques and Bleyer, J{\'e}r{\'e}my and Feld-Payet, Sylvia and Gourgues-Lorenzon, Anne-Fran{\c{c}}oise and Hannard, Florent and Helfer, Thomas and Hure, Jeremy and Kondo, Djimedo and Lazarus, Veronique and Le Bourlot, Christophe and others},
  year={2023},
  publisher={CERN-European Organization for Nuclear Research}
}
